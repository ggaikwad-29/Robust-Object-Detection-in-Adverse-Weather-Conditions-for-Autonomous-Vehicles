# -*- coding: utf-8 -*-
"""CV_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yVkxfk6_9f6AsAHPoVc7nQFP7xIbEblU

Robust Object Detection

Step 1 : Setting up the Environment
"""

import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt
import torchvision
import json
import multiprocessing

"""step 2 : Downloading the dataset from Kaggle"""

!pip install kaggle

from google.colab import files
import sys
import os
from kaggle.api.kaggle_api_extended import KaggleApi
import random
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import Compose, ToTensor, Normalize, Resize, ColorJitter, RandomApply
from PIL import Image
import urllib.request

import torch.nn as nn
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.backbone_utils import resnet_fpn_backbone
import torch.nn.functional as F
from torchvision.models import resnet34

print("Please upload your 'kaggle.json' file to access the BDD100K dataset from Kaggle.")
uploaded = files.upload()

# Checking if a file was uploaded
if not uploaded:
    print("Error: No file uploaded. Please upload your kaggle.json file.")
    sys.exit(1)

# Defining Kaggle configuration directory
kaggle_config_dir = os.path.expanduser("~/.config/kaggle")

# Creating the directory where Kaggle expects the configuration file
os.makedirs(kaggle_config_dir, exist_ok=True)

# Moveing the uploaded kaggle.json file to the correct directory and set permissions
!cp kaggle.json ~/.config/kaggle/
!chmod 600 ~/.config/kaggle/kaggle.json

# Checking if the file exists in the expected location
if os.path.exists('/root/.config/kaggle/kaggle.json'):
    print("kaggle.json found in /root/.config/kaggle/")
else:
    print("kaggle.json not found. Please ensure it was uploaded and placed correctly.")
    sys.exit(1)

# Authenticating with Kaggle API
api = KaggleApi()
api.authenticate()

# Setting the download path
download_path = '/content/bdd100k'

# Checking if dataset already exists to prevent re-downloading
if not os.path.exists(download_path):
    print("Downloading the BDD100K dataset. This might take a while...")
    api.dataset_download_files('solesensei/solesensei_bdd100k', path=download_path, unzip=True)
    print("Download completed.")
else:
    print("Dataset already exists at:", download_path)

img_dir = '/content/bdd100k/bdd100k/bdd100k/images/10k/train'
img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]
print(f"Number of images in {img_dir}: {len(img_files)}")

img_dir = '/content/bdd100k/bdd100k/bdd100k/images/10k/train'
img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')][:10]  # First 10 images

# Setting up the plot grid (2 rows, 5 columns)
fig, axes = plt.subplots(2, 5, figsize=(15, 6))

# Loop through the first 10 images and display them
for i, img_file in enumerate(img_files):
    img_path = os.path.join(img_dir, img_file)
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

    # Ploting image
    ax = axes[i // 5, i % 5]  # Determine subplot position
    ax.imshow(img_rgb)
    ax.axis('off')
    ax.set_title(f"Image {i+1}")

plt.tight_layout()
plt.show()

"""Step 3 : Dataset Preprocessing"""

import os
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, Subset
from torchvision import transforms
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.backbone_utils import resnet_fpn_backbone
from PIL import Image
import cv2
import numpy as np
import matplotlib.pyplot as plt
from torch.cuda.amp import autocast, GradScaler

# Dataset Class for Loading Images
class SimpleImageDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]
        self.transform = transform

    def __len__(self):
        return len(self.img_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_files[idx])
        try:
            # Load image and convert to RGB
            image = Image.open(img_path).convert("RGB")

            # Apply transformations (e.g., ToTensor, Resize)
            if self.transform:
                image = self.transform(image)

            return image  # Return a single tensor
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
            return None

# Collating function for handling batched data
def collate_fn(batch):
    # Filter out None values from the batch
    batch = [b for b in batch if b is not None]
    return torch.stack(batch)

# Preprocessing: Transformations and Augmentations
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.RandomApply([transforms.GaussianBlur(kernel_size=5)], p=0.5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Loading Image Directories
train_dir = '/content/bdd100k/bdd100k/bdd100k/images/10k/train'
val_dir = '/content/bdd100k/bdd100k/bdd100k/images/10k/val'
test_dir = '/content/bdd100k/bdd100k/bdd100k/images/10k/test'

# Dataset and DataLoader with reduced dataset size for faster experimentation
train_dataset = SimpleImageDataset(train_dir, transform=transform)
val_dataset = SimpleImageDataset(val_dir, transform=transform)
test_dataset = SimpleImageDataset(test_dir, transform=transform)

# Reducing dataset size to speed up experimentation
clear_dataset = Subset(train_dataset, indices=range(0, 100))
train_loader = DataLoader(clear_dataset, batch_size=16, shuffle=True, num_workers=4, collate_fn=collate_fn)

# Showing Images (Optional)
def show_images(images, n=5):
    fig, axs = plt.subplots(1, n, figsize=(15, 5))
    for i in range(n):
        axs[i].imshow(images[i].permute(1, 2, 0).numpy())
        axs[i].axis('off')
    plt.show()

sample_batch = next(iter(train_loader))
show_images(sample_batch[:5], n=5)

"""Multi-Sensor Fusion Framework for Robust Object Detection"""

# Multi-Sensor Fusion: Depth Map Generation
def generate_depth_map(image):
    # Converting tensor to NumPy (move to CPU if necessary)
    image_np = image.cpu().numpy().transpose(1, 2, 0) * 255
    image_np = image_np.astype('uint8')

    # Converting to grayscale and apply Sobel edge detection
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)
    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)
    depth_map = cv2.magnitude(sobel_x, sobel_y)
    depth_map = cv2.normalize(depth_map, None, 0, 1, cv2.NORM_MINMAX)

    return torch.tensor(depth_map, dtype=torch.float32).unsqueeze(0)

# Thermal Image Generation
def generate_thermal_image(image):
    # Converting tensor to NumPy (move to CPU if necessary)
    image_np = image.cpu().numpy().transpose(1, 2, 0) * 255
    image_np = image_np.astype('uint8')

    # Converting to grayscale and apply thermal colormap
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    thermal_image = cv2.applyColorMap(gray, cv2.COLORMAP_JET)

    return torch.tensor(thermal_image, dtype=torch.float32).permute(2, 0, 1) / 255.0

# Preprocessing: Combining RGB, Depth, and Thermal Information
def preprocess_input(images):
    device = images.device  # Ensure all tensors are on the same device

    # Generating depth and thermal maps
    depth_maps = torch.stack([generate_depth_map(img).to(device) for img in images])
    thermal_images = torch.stack([generate_thermal_image(img).to(device) for img in images])

    # Resizing all components to the same shape
    images = F.interpolate(images, size=(128, 128), mode='bilinear', align_corners=False)
    depth_maps = F.interpolate(depth_maps, size=(128, 128), mode='bilinear', align_corners=False)
    thermal_images = F.interpolate(thermal_images, size=(128, 128), mode='bilinear', align_corners=False)

    # Concatenating RGB, depth, and thermal channels
    return torch.cat([images, depth_maps, thermal_images], dim=1)

# Configuring Device (GPU or CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Creating a custom backbone with 7 input channels (RGB + Depth + Thermal)
backbone = resnet_fpn_backbone('resnet50', pretrained=True)
backbone.body.conv1 = torch.nn.Conv2d(7, 64, kernel_size=7, stride=2, padding=3, bias=False)
# Initializing Faster R-CNN
model = FasterRCNN(backbone, num_classes=2)
model = model.to(device)

# Defining Optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)

# Mixed Precision Training Setup
scaler = GradScaler()

# Training Loop with Gradient Accumulation
num_epochs = 10
gradient_accumulation_steps = 2

for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    print(f"Epoch {epoch + 1}/{num_epochs} started...")

    for i, images in enumerate(train_loader):
        images = images.to(device)

        # Preprocessing input
        images = preprocess_input(images)

        optimizer.zero_grad()

        # Mixed Precision: Use autocast for automatic precision handling
        with autocast():
            # Forward pass: Get features from the backbone
            features = model.backbone(images)

            # Optional: Resize feature maps for memory efficiency
            largest_size = (features['0'].shape[-2] // 2, features['0'].shape[-1] // 2)
            resized_features = [
                F.interpolate(f, size=largest_size, mode='bilinear', align_corners=False)
                for f in features.values()
            ]
            combined_features = torch.cat(resized_features, dim=1)

            # Computing self-supervised loss (e.g., MSE loss)
            with torch.no_grad():
                target_features = combined_features.clone()
            loss = F.mse_loss(combined_features, target_features)

        # Scale loss by accumulation steps
        loss = loss / gradient_accumulation_steps

        # Backward pass and gradient accumulation
        scaler.scale(loss).backward()
        if (i + 1) % gradient_accumulation_steps == 0:
            scaler.step(optimizer)
            scaler.update()

        total_loss += loss.item()

    print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}")

import random
import matplotlib.pyplot as plt
from torchvision import transforms
import numpy as np
import torch

def show_random_images(dataset, transform, num_images=3):
    # Randomly select 3 images from the dataset
    random_indices = random.sample(range(len(dataset)), num_images)

    # Get the images corresponding to the random indices
    images = [dataset[i] for i in random_indices]

    # Apply the transformation to each image and prepare for plotting
    fig, axs = plt.subplots(num_images, 2, figsize=(10, 5 * num_images))

    for i, image in enumerate(images):
        # Extract original image (before transformation)
        original_image = image

        # Check if the original image is already a tensor and convert it to PIL Image if needed
        if isinstance(original_image, torch.Tensor):
            original_image = transforms.ToPILImage()(original_image)

        # Apply the transformation to the image
        transformed_image = transform(original_image)

        # Convert tensors to numpy arrays for displaying
        original_image = np.array(original_image)
        transformed_image = transformed_image.permute(1, 2, 0).numpy()

        # Display the original image
        axs[i, 0].imshow(original_image)
        axs[i, 0].set_title(f"Original Image {i+1}")
        axs[i, 0].axis('off')

        # Display the transformed image
        axs[i, 1].imshow(transformed_image)
        axs[i, 1].set_title(f"Transformed Image {i+1}")
        axs[i, 1].axis('off')

    plt.tight_layout()
    plt.show()

# Example usage: Show 3 random images with original and transformed images
show_random_images(train_dataset, transform, num_images=3)

"""Image Quality Enhancement"""

import cv2
import numpy as np
import os
import matplotlib.pyplot as plt

# Placeholder de-hazing function
def dehaze_image(image):
    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance luminance
    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)

    # Apply CLAHE to the L-channel
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)

    # Merge channels and convert back to RGB
    lab = cv2.merge((l, a, b))
    dehazed = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
    return dehazed

# Path to the image directory
img_dir = '/content/bdd100k/bdd100k/bdd100k/images/10k/train'
img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')][:10]

# Set up the plot grid (2 rows, 5 columns)
fig, axes = plt.subplots(2, 5, figsize=(15, 6))

# Loop through the first 10 images and display de-hazed results
for i, img_file in enumerate(img_files):
    img_path = os.path.join(img_dir, img_file)
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Apply the de-hazing function
    dehazed_img = dehaze_image(img_rgb)

    # Plot the de-hazed image
    ax = axes[i // 5, i % 5]
    ax.imshow(dehazed_img)
    ax.axis('off')
    ax.set_title(f"De-Hazed Image {i+1}")

plt.tight_layout()
plt.show()

import os
import random
import torch
import matplotlib.pyplot as plt
import cv2
import numpy as np

# Define the DeRainNet model (placeholder)
class DeRainNet(torch.nn.Module):
    def __init__(self):
        super(DeRainNet, self).__init__()


    def forward(self, x):

        return x

# Function to de-rain an image using the model
def derain_image(image_tensor):
    model = DeRainNet()
    model.eval()

    # Normalize and convert to byte range
    image_tensor = image_tensor * 255.0
    image_tensor = image_tensor.byte()

    with torch.no_grad():
        enhanced_image = model(image_tensor.unsqueeze(0))

    # Convert back to numpy array (remove batch dimension)
    enhanced_image = enhanced_image.squeeze().cpu().numpy()

    return enhanced_image

# Function to randomly select an image from a directory
def get_random_image(folder_path):
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not image_files:
        raise FileNotFoundError(f"No images found in {folder_path}")
    return os.path.join(folder_path, random.choice(image_files))

# Convert OpenCV image to normalized tensor
def image_to_tensor(image):
    # Convert image to float32, normalize to [0, 1], and permute dimensions
    image = image.astype(np.float32) / 255.0
    return torch.from_numpy(image).permute(2, 0, 1)

# Convert tensor back to image for visualization
def tensor_to_image(tensor):
    tensor = tensor.clamp(0, 1)  # Ensure values are in [0, 1]
    return (tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)

# Randomly select and process an image
img_dir = "/content/bdd100k/bdd100k/bdd100k/images/10k/train"
img_path = get_random_image(img_dir)
original_image = cv2.imread(img_path)
original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)

# Convert the image to a tensor
image_tensor = image_to_tensor(original_image)

# Apply the deraining function
derained_tensor = derain_image(image_tensor)

# Convert the de-rained tensor back to an image
derained_image = tensor_to_image(torch.tensor(derained_tensor))

# Display original and de-rained images side by side
plt.figure(figsize=(10, 5))

# Original image
plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(original_image)
plt.axis("off")

# De-rained image
plt.subplot(1, 2, 2)
plt.title("De-Rained Image")
plt.imshow(derained_image)
plt.axis("off")

plt.tight_layout()
plt.show()

print(f"Randomly selected image: {img_path}")

import os
import random
import torch
import matplotlib.pyplot as plt
import cv2
import numpy as np

# Define the DeSnowNet model (placeholder)
class DeSnowNet(torch.nn.Module):
    def __init__(self):
        super(DeSnowNet, self).__init__()


    def forward(self, x):

        return x

# Function to de-snow an image using the model
def desnow_image(image_tensor):
    model = DeSnowNet()
    model.eval()

    # Normalize and convert to byte range
    image_tensor = image_tensor * 255.0
    image_tensor = image_tensor.byte()

    with torch.no_grad():
        enhanced_image = model(image_tensor.unsqueeze(0))

    # Convert back to numpy array (remove batch dimension)
    enhanced_image = enhanced_image.squeeze().cpu().numpy()

    return enhanced_image

# Function to randomly select an image from a directory
def get_random_image(folder_path):
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not image_files:
        raise FileNotFoundError(f"No images found in {folder_path}")
    return os.path.join(folder_path, random.choice(image_files))

# Convert OpenCV image to normalized tensor
def image_to_tensor(image):
    # Convert image to float32, normalize to [0, 1], and permute dimensions
    image = image.astype(np.float32) / 255.0
    return torch.from_numpy(image).permute(2, 0, 1)

# Convert tensor back to image for visualization
def tensor_to_image(tensor):
    tensor = tensor.clamp(0, 1)
    return (tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)

# Randomly select and process an image
img_dir = "/content/bdd100k/bdd100k/bdd100k/images/10k/train"
img_path = get_random_image(img_dir)
original_image = cv2.imread(img_path)
original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)

# Convert the image to a tensor
image_tensor = image_to_tensor(original_image)

# Apply the de-snowing function
desnowed_tensor = desnow_image(image_tensor)

# Convert the de-snowed tensor back to an image
desnowed_image = tensor_to_image(torch.tensor(desnowed_tensor))

# Display original and de-snowed images side by side
plt.figure(figsize=(10, 5))

# Original image
plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(original_image)
plt.axis("off")

# De-snowed image
plt.subplot(1, 2, 2)
plt.title("De-Snowed Image")
plt.imshow(desnowed_image)
plt.axis("off")

plt.tight_layout()
plt.show()

print(f"Randomly selected image: {img_path}")

"""dynamic retraining"""

import torch
from torch.utils.data import DataLoader, Subset
from torchvision import transforms
import numpy as np
from PIL import Image
import os
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torch import optim

# Device setup (make sure you're using CUDA if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Load the pre-trained Faster R-CNN model
model = fasterrcnn_resnet50_fpn(pretrained=True).to(device)
num_classes = 2  # 1 class (edge case) + background
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)

# Define the optimizer
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# Freeze backbone layers (only train the ROI heads)
for param in model.backbone.parameters():
    param.requires_grad = False

# Define the transformation for data preprocessing
transform = transforms.Compose([
    transforms.Resize((800, 800)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Custom Dataset class to handle edge case images
class WeatherEdgeCaseDataset(torch.utils.data.Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.images[idx])
        image = Image.open(img_name).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image

# Subset dataset function
def get_subset(dataset, subset_size):
    indices = np.random.choice(len(dataset), subset_size, replace=False)
    return Subset(dataset, indices)

# Subset sizes
train_subset_size = 500
val_subset_size = 200
edge_case_subset_size = 50

# Create subsets for training, validation, and edge case data
train_subset = get_subset(train_dataset, train_subset_size)
val_subset = get_subset(val_dataset, val_subset_size)

# Subset DataLoaders
train_loader = DataLoader(train_subset, batch_size=4, shuffle=True, num_workers=2)
val_loader = DataLoader(val_subset, batch_size=4, shuffle=False, num_workers=2)

# Edge case directory
edge_case_dir = "/content/bdd100k/bdd100k/bdd100k/images/edge_cases"
edge_case_dataset = WeatherEdgeCaseDataset(edge_case_dir, transform=transform)

# Create the edge case subset and DataLoader
edge_case_subset = get_subset(edge_case_dataset, edge_case_subset_size)
edge_case_loader = DataLoader(edge_case_subset, batch_size=4, shuffle=True, num_workers=2)

# Dynamic retraining function
def dynamic_retraining(model, edge_case_loader, train_loader, val_loader, epochs=3):
    for epoch in range(epochs):
        model.train()
        total_loss = 0

        print(f"\nEpoch {epoch + 1}/{epochs}: Retraining with edge cases...")

        # Retraining with edge cases
        for i, images in enumerate(edge_case_loader):
            images = images.to(device)

            # Generate dummy targets for edge case retraining (can be replaced with actual targets if available)
            targets = [{"boxes": torch.zeros(0, 4).to(device), "labels": torch.zeros(0).long().to(device)}] * len(images)

            # Forward pass
            outputs = model(images, targets)
            loss = sum(loss for loss in outputs.values())

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

            if i % 10 == 0:  # Print progress every 10 batches
                print(f"Batch {i} - Loss: {loss.item():.4f}")

        print(f"Retraining Epoch {epoch + 1} Loss: {total_loss / len(edge_case_loader):.4f}")


# Perform dynamic retraining
dynamic_retraining(model, edge_case_loader, train_loader, val_loader, epochs=1)

# Save the retrained model
torch.save(model.state_dict(), "faster_rcnn_dynamic_retrained.pth")
print("Model retrained and saved.")

"""Evaluation"""

import numpy as np
import time

# Function to calculate IoU (Intersection over Union)
def calculate_iou(box1, box2):

    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])

    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = box1_area + box2_area - intersection

    return intersection / union if union > 0 else 0

# Function to calculate precision and recall
def calculate_precision_recall(pred_boxes, gt_boxes, iou_threshold=0.5):

    tp, fp, fn = 0, 0, len(gt_boxes)
    detected = set()

    for pred in pred_boxes:
        iou_max = 0
        matched_gt = -1
        for i, gt in enumerate(gt_boxes):
            iou = calculate_iou(pred[:4], gt)
            if iou > iou_max:
                iou_max = iou
                matched_gt = i
        if iou_max >= iou_threshold and matched_gt not in detected:
            tp += 1
            detected.add(matched_gt)
            fn -= 1
        else:
            fp += 1

    precision = tp / (tp + fp) if tp + fp > 0 else 0
    recall = tp / (tp + fn) if tp + fn > 0 else 0
    return precision, recall

# Function to calculate mean Average Precision (mAP)
def calculate_map(predictions, ground_truths, iou_thresholds=np.linspace(0.5, 0.95, 10)):

    ap_list = []
    for iou_threshold in iou_thresholds:
        precision_list = []
        for pred_boxes, gt_boxes in zip(predictions, ground_truths):
            precision, _ = calculate_precision_recall(pred_boxes, gt_boxes, iou_threshold)
            precision_list.append(precision)
        ap = np.mean(precision_list) if precision_list else 0
        ap_list.append(ap)
    return np.mean(ap_list)

# Function to calculate robustness
def calculate_robustness(predictions, variations):

    return np.mean([np.mean(metrics) for metrics in predictions])

# Function to calculate FPS (Frames Per Second)
def calculate_fps(model, input_data, num_samples=100):

    start_time = time.time()
    for _ in range(num_samples):
        _ = model(input_data)  # Run inference
    end_time = time.time()
    elapsed_time = end_time - start_time
    return num_samples / elapsed_time

# Example Usage
# Predictions and ground truths should be in the format [[x1, y1, x2, y2, score], ...]
predictions = [
    [[50, 50, 150, 150, 0.9], [30, 30, 100, 100, 0.8]],
    [[20, 20, 70, 70, 0.95]]
]
ground_truths = [
    [[50, 50, 150, 150], [30, 30, 100, 100]],
    [[20, 20, 70, 70]]
]

# Example calls
map_score = calculate_map(predictions, ground_truths)
print("mAP:", map_score)

# Assuming a dummy model for FPS calculation
class DummyModel:
    def __call__(self, input_data):
        return input_data  # Simulate a dummy inference

model = DummyModel()
input_data = np.zeros((3, 224, 224))  # Example input
fps = calculate_fps(model, input_data)
print("FPS:", fps)

# Ground truth and predictions for two variations
predictions = [
    [[50, 50, 150, 150, 0.9], [30, 30, 100, 100, 0.8]],
    [[20, 20, 70, 70, 0.95]]
]
ground_truths = [
    [[50, 50, 150, 150], [30, 30, 100, 100]],
    [[20, 20, 70, 70]]
]

# Precision and Recall
precision, recall = calculate_precision_recall(predictions[0], ground_truths[0], iou_threshold=0.5)
print("Precision:", precision)
print("Recall:", recall)

# Robustness example with two variations
predictions_variations = [predictions, predictions]  # Simulating predictions under variations
ground_truths_variations = [ground_truths, ground_truths]  # Reusing GTs for simplicity

precision_scores = []
for pred, gt in zip(predictions_variations, ground_truths_variations):
    precisions = []
    for p, g in zip(pred, gt):
        precision, _ = calculate_precision_recall(p, g)
        precisions.append(precision)
    precision_scores.append(precisions)

robustness = calculate_robustness(precision_scores, variations=["Variation 1", "Variation 2"])
print("Robustness Score:", robustness)
